# ğŸš€ AnÃ¡lisis Comparativo de Algoritmos: Ordenamiento y BÃºsqueda

---

## **Autores:** 
- GonzÃ¡lez GonzÃ¡lez Erick Emiliano
- De La Rosa HernÃ¡ndez Tania
<br></br>
Curso: AnÃ¡lisis y DiseÃ±o de Algoritmos
<br></br>
Fecha: Febrero 2026

---

## ğŸ“ IntroducciÃ³n
Esta prÃ¡ctica tiene como objetivo evaluar empÃ­ricamente la **complejidad computacional** (Tiempo y Espacio) de seis algoritmos clÃ¡sicos; 3 de ordenamiento y 3 de bÃºsqueda. A travÃ©s de pruebas con volÃºmenes de datos masivos (hasta $10,000,000$ de elementos), se busca contrastar la teorÃ­a asintÃ³tica con el rendimiento real en hardware promedio.

---

## ğŸ“š Estructura del repositorio

```bash
PrÃ¡ctica1_IntroducciÃ³n_a_la_complejidad/
â”‚
â”œâ”€â”€ ğŸ“‚ Ordenamiento/               # Implementaciones individuales en C++
â”‚   â”œâ”€â”€ BubbleSort.cpp
â”‚   â”œâ”€â”€ MergeSort.cpp
â”‚   â””â”€â”€ QuickSort.cpp
â”‚
â”œâ”€â”€ ğŸ“‚ Busqueda/                   # Implementaciones individuales en Python
â”‚   â”œâ”€â”€ BusquedaLineal.py
â”‚   â”œâ”€â”€ BusquedaBinaria.py
â”‚   â””â”€â”€ BusquedaPorSalto.py
â”‚
â”œâ”€â”€ ğŸ“œ CÃ³digoMaestroOrdenamiento.cpp     # CÃ³digo maestro: ejecuta pruebas y genera CSV
â”œâ”€â”€ ğŸ“œ CÃ³digoMaestroBusqueda.py          # CÃ³digo maestro: ejecuta pruebas y genera CSV
â”œâ”€â”€ ğŸ“Š resultados_ordenamiento.csv  # Datos generados por C++
â”œâ”€â”€ ğŸ“Š resultados_busqueda.csv      # Datos generados por Python
â””â”€â”€ ğŸ“˜ README.md                    # DocumentaciÃ³n del proyecto
```

---

## ğŸ› ï¸ Especificaciones del Entorno de Pruebas

Para garantizar la precisiÃ³n de los resultados, se separaron las responsabilidades tecnolÃ³gicas de la siguiente manera:

### 1. Desarrollo en C++ (Foco: Rendimiento)
* **Uso:** ImplementaciÃ³n de algoritmos de ordenamiento.
* **JustificaciÃ³n:** La gestiÃ³n manual de memoria y la velocidad de ejecuciÃ³n de un lenguaje compilado son crÃ­ticas cuando se procesan estructuras de datos de $40\text{ MB}$ o mÃ¡s. Se utilizÃ³ la librerÃ­a `<chrono>` para mediciones de alta precisiÃ³n.

### 2. Desarrollo en Python (Foco: AnÃ¡lisis y Flexibilidad)
* **Uso:** ImplementaciÃ³n de algoritmos de bÃºsqueda.
* **JustificaciÃ³n:** Python permite una rÃ¡pida manipulaciÃ³n de datos y la generaciÃ³n automatizada de reportes CSV. Se utilizÃ³ `time.perf_counter_ns()` para capturar diferencias de tiempo en escala de nanosegundos.

---

## ğŸ“ˆ SecciÃ³n 1: Algoritmos de Ordenamiento (C++)

Se seleccionaron tres algoritmos con comportamientos contrastantes segÃºn la NotaciÃ³n Big O.

### 1.1. Tabla Comparativa de Tiempos (ms)

| TamaÃ±o (N) | Bubble Sort ( $O(n^2)$ ) | Merge Sort ( $O(n \log n)$ ) | QuickSort ( $O(n \log n)$ ) |
|------------|-------------------------|----------------------------|---------------------------|
| 10         | 0                       | 0                          | 0                         |
| 100        | 0                       | 0                          | 0                         |
| 1,000      | 4                       | 0                          | 0                         |
| 10,000     | 357                     | 4                          | 1                         |
| 100,000    | **Inviable (INF)**      | 42                         | 24                        |
| 1,000,000  | **Inviable (INF)**      | 501                        | 195                       |
| 10,000,000 | **Inviable (INF)**      | 5395                       | 4540                      |



### 1.2. AnÃ¡lisis de Consumo de Memoria
* **Bubble Sort:** Complejidad espacial $O(1)$. Solo requiere el espacio del arreglo original.
* **QuickSort:** Complejidad espacial $O(\log n)$ debido a la profundidad de la pila de recursiÃ³n.
* **Merge Sort:** Complejidad espacial $O(n)$. Es el mÃ¡s costoso, ya que requiere un arreglo auxiliar del mismo tamaÃ±o que el original para realizar la mezcla de sub-arreglos.
  * *Ejemplo:* Para $10^7$ enteros, Merge Sort utiliza $\approx 80\text{ MB}$ de RAM total.

### 1.3. GrÃ¡fico de AnÃ¡lisis

<p align="center">
<img width="818" height="482" alt="Imagen2" src="https://github.com/user-attachments/assets/9fcef2a9-c423-4617-931a-4bed0dd91ead" />
<br>
<em>Figura 1: Comparativa de tiempos en milisegundos. NÃ³tese la divergencia exponencial del Bubble Sort frente a los mÃ©todos basados en particiÃ³n.</em>
</p>

**DescripciÃ³n TÃ©cnica:**
Este grÃ¡fico ilustra la evoluciÃ³n del tiempo de ejecuciÃ³n de los algoritmos **Bubble Sort**, **Merge Sort** y **QuickSort** conforme aumenta el tamaÃ±o del arreglo ($N$).

* **Comportamiento CuadrÃ¡tico:** Se observa cÃ³mo la lÃ­nea de **Bubble Sort ( $O(n^2)$ )** mantiene una pendiente pronunciada y constante en la escala logarÃ­tmica. Al escalar hacia los $10^7$ elementos, su tiempo se dispara a valores inviables (representados por la tendencia hacia los 350,000 ms, para fines prÃ¡cticos del grÃ¡fico, sin embargo en un entorno real los tiempos se extienden a las horas e incluso dÃ­as), confirmando su ineficiencia para el procesamiento de grandes volÃºmenes de datos.
* **Eficiencia LogarÃ­tmica:** Las curvas de **QuickSort** y **Merge Sort ( $O(n \log n)$ )** se mantienen significativamente por debajo de la curva de Bubble Sort. 
* **OptimizaciÃ³n PrÃ¡ctica:** QuickSort demostrÃ³ ser el mÃ¡s Ã³ptimo, logrando procesar los 10 millones de registros en aproximadamente **4,540 ms**, superando ligeramente a Merge Sort (**5,395 ms**) debido a su menor factor de constante y mejor aprovechamiento de la memoria cachÃ©.

---

## ğŸ” SecciÃ³n 2: Algoritmos de BÃºsqueda (Python)

Las pruebas se realizaron sobre arreglos previamente ordenados para permitir el funcionamiento de los mÃ©todos logarÃ­tmicos.

### 2.1. Tabla de Rendimiento (ns)
| TamaÃ±o (N) | Lineal ( $O(n)$ ) | Salto/Jump ( $O(\sqrt{n})$ ) | Binaria ( $O(\log n)$ ) |
|------------|-------------------------|----------------------------|---------------------------|
| 10         | 2200                    | 5700                       | 2000                      |
| 100        | 3700                    | 1500                       | 1400                      |
| 1,000      | 27400                   | 1000                       | 1700                      |
| 10,000     | 262900                  | 1400                       | 2700                      |
| 100,000    | 2634000                 | 1400                       | 3100                      |
| 1,000,000  | 27295200                | 7300                       | 12200                     |
| 10,000,000 | 270264600               | 6300                       | 11400                     |

### 2.2. AnÃ¡lisis de Consumo de Memoria (BÃºsqueda)

A diferencia de los algoritmos de ordenamiento, que a menudo requieren duplicar datos o gestionar pilas de recursiÃ³n, los algoritmos de bÃºsqueda seleccionados se caracterizan por ser sumamente eficientes en el uso de memoria auxiliar (espacio extra requerido ademÃ¡s de la estructura de datos original).

* **BÃºsqueda Lineal:** Complejidad espacial **$O(1)$**. El algoritmo opera de forma iterativa y solo requiere una variable de control (Ã­ndice) para recorrer la lista. El consumo de memoria es constante e independiente del tamaÃ±o del arreglo ($N$).
* **BÃºsqueda por Salto (Jump Search):** Complejidad espacial **$O(1)$**. Requiere Ãºnicamente dos variables adicionales de tipo entero: una para definir el tamaÃ±o del bloque de salto ($\sqrt{n}$) y otra para rastrear la posiciÃ³n previa dentro del bloque.
* **BÃºsqueda Binaria:** Complejidad espacial **$O(1)$**. Al implementarse de forma iterativa (usando un ciclo `while`), solo reserva espacio para tres Ã­ndices: `izq`, `der` y `medio`. Al no utilizar recursividad en esta implementaciÃ³n, no genera sobrecarga en la pila de llamadas (*stack memory*), manteniendo un consumo mÃ­nimo y fijo.

> **Nota TÃ©cnica sobre el entorno (Python):** > Es fundamental distinguir entre la complejidad del *algoritmo* y el costo de la *estructura de datos*. Aunque los algoritmos son $O(1)$, una lista de $10^7$ enteros en Python consume significativamente mÃ¡s memoria que un `vector<int>` en C++. Esto se debe al "overhead" de los objetos en Python (cada entero es un objeto con metadatos), elevando el consumo base a un rango de **$80\text{ MB} - 160\text{ MB}$** en sistemas de 64 bits.

### 2.3. GrÃ¡fico de AnÃ¡lisis

<p align="center">
<img width="818" height="499" alt="Imagen1" src="https://github.com/user-attachments/assets/999604c0-e552-48ef-9f79-eaecb7bce242" />
<br>
<em>Figura 2: Comparativa de tiempos en milisegundos. NÃ³tese la divergencia exponencial de la Busqueda Lineal frente a los otros mÃ©todos.</em>
</p>

**DescripciÃ³n TÃ©cnica:**
El grÃ¡fico compara el tiempo de respuesta de los mÃ©todos de bÃºsqueda sobre arreglos ordenados de hasta $10^7$ elementos, utilizando nanosegundos (ns) como unidad de medida.

* **BÃºsqueda Lineal ( $O(n)$ ):** Representada por la lÃ­nea azul superior, muestra un crecimiento lineal perfecto. Al requerir la inspecciÃ³n de cada elemento en el peor de los casos, el tiempo aumenta en proporciÃ³n directa al tamaÃ±o del arreglo, alcanzando los **270,264,600 ns** en la prueba mÃ¡xima.
* **BÃºsqueda Binaria ( $O(\log n)$ ):** Situada en la parte inferior (lÃ­nea naranja), demuestra una eficiencia asintÃ³tica superior. A pesar de aumentar el tamaÃ±o del arreglo un millÃ³n de veces, el tiempo de bÃºsqueda apenas varÃ­a, manteniÃ©ndose en una escala de microsegundos, lo que valida su complejidad logarÃ­tmica.
* **BÃºsqueda por Salto ( $O(\sqrt{n})$ ):** La lÃ­nea verde muestra un rendimiento intermedio. Es notablemente mÃ¡s eficiente que la bÃºsqueda lineal pero menos optimizada que la binaria, sirviendo como un balance tÃ©cnico que confirma su posiciÃ³n teÃ³rica entre $O(n)$ y $O(\log n)$.

---

## ğŸ§  Conclusiones

### A. La Barrera del Rendimiento CuadrÃ¡tico
Los resultados muestran que el **Bubble Sort** experimenta un crecimiento explosivo. Al pasar de $10^4$ a $10^5$ elementos, el tiempo de procesamiento se multiplica por 100, validando la naturaleza de $n^2$. En aplicaciones industriales o de Big Data, este algoritmo es estrictamente teÃ³rico.

### B. QuickSort vs. Merge Sort
Aunque ambos comparten una complejidad promedio de $O(n \log n)$, **QuickSort** superÃ³ consistentemente a Merge Sort en tiempo. Esto se debe a que QuickSort tiene un factor de constante menor y no requiere la sobrecarga de memoria que implica crear copias de sub-arreglos en cada divisiÃ³n.

### C. Eficiencia de BÃºsqueda
La **BÃºsqueda Binaria** es el ejemplo mÃ¡ximo de optimizaciÃ³n. Mientras que la BÃºsqueda Lineal debe inspeccionar $10,000,000$ de elementos en el peor caso, la BÃºsqueda Binaria localiza el objetivo en un mÃ¡ximo de **24 comparaciones**, lo que reduce el tiempo de ejecuciÃ³n a una fracciÃ³n casi imperceptible de segundo.

---

## ğŸ› ï¸ Instrucciones de EjecuciÃ³n
1. Clona el repositorio con: `git clone https://github.com/ZkDrxzyy/P1_Sorting-And-Searching-Algorithms-Complexities`
2. Compila los archivos de C++ usando `g++`.
3. Ejecuta los scripts de Python con `python3`.
